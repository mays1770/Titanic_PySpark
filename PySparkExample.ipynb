{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "conf = pyspark.SparkConf().setAppName('appName').setMaster('local')\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format('csv').options(header='true', inferSchema='true').load('C:/_Emory/1_676-Machine Learning II/Assignments/HW2/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|null|    0|    0|          330877| 8.4583| null|       Q|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| null|       S|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| null|       S|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| null|       C|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55| C103|       S|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05| null|       S|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275| null|       S|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542| null|       S|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0| null|       S|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125| null|       Q|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|null|    0|    0|          244373|   13.0| null|       S|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0| null|       S|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|null|    0|    0|            2649|  7.225| null|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "891"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i) Print the dataset and verify that the schema contains all the variables\n",
    "df.show()\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|null|    0|    0|          330877| 8.4583| null|       Q|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| null|       S|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| null|       S|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| null|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ii) Print the first 10 rows from the dataset. \n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n",
      "|summary|      PassengerId|           Survived|            Pclass|                Name|   Sex|               Age|             SibSp|              Parch|            Ticket|             Fare|Cabin|Embarked|\n",
      "+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n",
      "|  count|              891|                891|               891|                 891|   891|               714|               891|                891|               891|              891|  204|     889|\n",
      "|   mean|            446.0| 0.3838383838383838| 2.308641975308642|                null|  null| 29.69911764705882|0.5230078563411896|0.38159371492704824|260318.54916792738| 32.2042079685746| null|    null|\n",
      "| stddev|257.3538420152301|0.48659245426485753|0.8360712409770491|                null|  null|14.526497332334035|1.1027434322934315| 0.8060572211299488|471609.26868834975|49.69342859718089| null|    null|\n",
      "|    min|                1|                  0|                 1|\"Andersson, Mr. A...|female|              0.42|                 0|                  0|            110152|              0.0|  A10|       C|\n",
      "|    max|              891|                  1|                 3|van Melkebeke, Mr...|  male|              80.0|                 8|                  6|         WE/P 5735|         512.3292|    T|       S|\n",
      "+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n",
      "\n",
      "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
      "|PassengerId|Survived|Pclass|Name|Sex|Age|SibSp|Parch|Ticket|Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
      "|          0|       0|     0|   0|  0|177|    0|    0|     0|   0|  687|       2|\n",
      "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('PassengerId', 'int'),\n",
       " ('Survived', 'int'),\n",
       " ('Pclass', 'int'),\n",
       " ('Name', 'string'),\n",
       " ('Sex', 'string'),\n",
       " ('Age', 'double'),\n",
       " ('SibSp', 'int'),\n",
       " ('Parch', 'int'),\n",
       " ('Ticket', 'string'),\n",
       " ('Fare', 'double'),\n",
       " ('Cabin', 'string'),\n",
       " ('Embarked', 'string')]"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iii) Obtain summary statistics for all variables in the dataframe. \n",
    "# Pay attention to whether there are missing data as well as whether the field appears to be continuous or discrete. \n",
    "df.describe().show()\n",
    "\n",
    "from pyspark.sql.functions import isnull, when, count, col\n",
    "df.select([count(when(isnull(c), c)).alias(c) for c in df.columns]).show()\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|   Sex|count|\n",
      "+------+-----+\n",
      "|  male|  577|\n",
      "|female|  314|\n",
      "+------+-----+\n",
      "\n",
      "+-----------+-----+\n",
      "|      Cabin|count|\n",
      "+-----------+-----+\n",
      "|       null|  687|\n",
      "|C23 C25 C27|    4|\n",
      "|         G6|    4|\n",
      "|    B96 B98|    4|\n",
      "|       E101|    3|\n",
      "|    C22 C26|    3|\n",
      "|        F33|    3|\n",
      "|         F2|    3|\n",
      "|          D|    3|\n",
      "|        C83|    2|\n",
      "+-----------+-----+\n",
      "only showing top 10 rows\n",
      "\n",
      "+--------+-----+\n",
      "|Embarked|count|\n",
      "+--------+-----+\n",
      "|       S|  644|\n",
      "|       C|  168|\n",
      "|       Q|   77|\n",
      "|    null|    2|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# iv) For each of the string columns (except name and ticket), print the count of the 10 most frequent values ordered by descending order of frequency.\n",
    "from pyspark.sql.functions import col, countDistinct\n",
    "df.groupby(df.Sex).count().distinct().sort('count',ascending=False).show()\n",
    "#df.groupby(df.Ticket).count().distinct().sort('count',ascending=False).show(10)\n",
    "df.groupby(df.Cabin).count().distinct().sort('count',ascending=False).show(10)\n",
    "df.groupby(df.Embarked).count().distinct().sort('count',ascending=False).show()\n",
    "\n",
    "#Useless code\n",
    "#train.select(\"Sex\").distinct().show()\n",
    "#train.agg(*(countDistinct(col(c)).alias(c) for c in train.columns)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v) Based on the above, which columns would you keep as features and which would you drop? Justify your answer. \n",
    "# drop cabin, because many missing values. 687/891\n",
    "# drop Name and Ticket, because I believe this is unrelated with our prediction\n",
    "# drop passenger_id, becasue this is just an row index\n",
    "# keep all other features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "891"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i) Select all feature columns you plan to use in addition to the target variable (i.e., ‘Survived’) and covert all numerical columns into double data type.\n",
    "#Tip: you can use the .cast() from pyspark.sql.functions. \n",
    "df=df.drop('cabin')\n",
    "df=df.drop('Name')\n",
    "df=df.drop('Ticket')\n",
    "df=df.drop('PassengerId')\n",
    "\n",
    "df = df.withColumn(\"SibSp\",df[\"SibSp\"].cast(\"double\"))\n",
    "df = df.withColumn(\"Parch\",df[\"Parch\"].cast(\"double\"))\n",
    "df = df.withColumn(\"Pclass\",df[\"Pclass\"].cast(\"double\"))\n",
    "\n",
    "df.dtypes\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+----+-----+-----+-------+--------+-----+\n",
      "|Survived|Pclass|   Sex| Age|SibSp|Parch|   Fare|Embarked|AgeNA|\n",
      "+--------+------+------+----+-----+-----+-------+--------+-----+\n",
      "|       0|   3.0|  male|22.0|  1.0|  0.0|   7.25|       S|  0.0|\n",
      "|       1|   1.0|female|38.0|  1.0|  0.0|71.2833|       C|  0.0|\n",
      "|       1|   3.0|female|26.0|  0.0|  0.0|  7.925|       S|  0.0|\n",
      "|       1|   1.0|female|35.0|  1.0|  0.0|   53.1|       S|  0.0|\n",
      "|       0|   3.0|  male|35.0|  0.0|  0.0|   8.05|       S|  0.0|\n",
      "|       0|   3.0|  male|29.7|  0.0|  0.0| 8.4583|       Q|  1.0|\n",
      "|       0|   1.0|  male|54.0|  0.0|  0.0|51.8625|       S|  0.0|\n",
      "|       0|   3.0|  male| 2.0|  3.0|  1.0| 21.075|       S|  0.0|\n",
      "|       1|   3.0|female|27.0|  0.0|  2.0|11.1333|       S|  0.0|\n",
      "|       1|   2.0|female|14.0|  1.0|  0.0|30.0708|       C|  0.0|\n",
      "|       1|   3.0|female| 4.0|  1.0|  1.0|   16.7|       S|  0.0|\n",
      "|       1|   1.0|female|58.0|  0.0|  0.0|  26.55|       S|  0.0|\n",
      "|       0|   3.0|  male|20.0|  0.0|  0.0|   8.05|       S|  0.0|\n",
      "|       0|   3.0|  male|39.0|  1.0|  5.0| 31.275|       S|  0.0|\n",
      "|       0|   3.0|female|14.0|  0.0|  0.0| 7.8542|       S|  0.0|\n",
      "|       1|   2.0|female|55.0|  0.0|  0.0|   16.0|       S|  0.0|\n",
      "|       0|   3.0|  male| 2.0|  4.0|  1.0| 29.125|       Q|  0.0|\n",
      "|       1|   2.0|  male|29.7|  0.0|  0.0|   13.0|       S|  1.0|\n",
      "|       0|   3.0|female|31.0|  1.0|  0.0|   18.0|       S|  0.0|\n",
      "|       1|   3.0|female|29.7|  0.0|  0.0|  7.225|       C|  1.0|\n",
      "+--------+------+------+----+-----+-----+-------+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "891"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ii) Replace the missing values in the Age column with the mean value. \n",
    "# Create also a new variable (e.g., ‘AgeNA’) indicating whether the value of age was missing or not. \n",
    "from pyspark.sql.functions import mean, avg\n",
    "from pyspark.sql import functions as F\n",
    "df=df.withColumn(\"AgeNA\",\n",
    "                       F.when((F.col(\"Age\").isNull()), 1)\\\n",
    "                        .otherwise(0))\n",
    "df=df.na.fill({'Age': 29.7})\n",
    "df = df.withColumn(\"AgeNA\",df[\"AgeNA\"].cast(\"double\"))\n",
    "df.show()\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+---+---+-----+-----+----+--------+-----+\n",
      "|Survived|Pclass|Sex|Age|SibSp|Parch|Fare|Embarked|AgeNA|\n",
      "+--------+------+---+---+-----+-----+----+--------+-----+\n",
      "|       0|     0|  0|  0|    0|    0|   0|       2|    0|\n",
      "+--------+------+---+---+-----+-----+----+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import isnull, when, count, col\n",
    "df.select([count(when(isnull(c), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "889"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deal with two null values in embarked, omit these two rows\n",
    "df=df.dropna()\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+----+-----+-----+-------+--------+-----+\n",
      "|Survived|Pclass|   Sex| Age|SibSp|Parch|   Fare|Embarked|AgeNA|\n",
      "+--------+------+------+----+-----+-----+-------+--------+-----+\n",
      "|       0|   3.0|  male|22.0|  1.0|  0.0|   7.25|       S|  0.0|\n",
      "|       1|   1.0|female|38.0|  1.0|  0.0|71.2833|       C|  0.0|\n",
      "|       1|   3.0|female|26.0|  0.0|  0.0|  7.925|       S|  0.0|\n",
      "|       1|   1.0|female|35.0|  1.0|  0.0|   53.1|       S|  0.0|\n",
      "|       0|   3.0|  male|35.0|  0.0|  0.0|   8.05|       S|  0.0|\n",
      "|       0|   3.0|  male|29.7|  0.0|  0.0| 8.4583|       Q|  1.0|\n",
      "|       0|   1.0|  male|54.0|  0.0|  0.0|51.8625|       S|  0.0|\n",
      "|       0|   3.0|  male| 2.0|  3.0|  1.0| 21.075|       S|  0.0|\n",
      "|       1|   3.0|female|27.0|  0.0|  2.0|11.1333|       S|  0.0|\n",
      "|       1|   2.0|female|14.0|  1.0|  0.0|30.0708|       C|  0.0|\n",
      "|       1|   3.0|female| 4.0|  1.0|  1.0|   16.7|       S|  0.0|\n",
      "|       1|   1.0|female|58.0|  0.0|  0.0|  26.55|       S|  0.0|\n",
      "|       0|   3.0|  male|20.0|  0.0|  0.0|   8.05|       S|  0.0|\n",
      "|       0|   3.0|  male|39.0|  1.0|  5.0| 31.275|       S|  0.0|\n",
      "|       0|   3.0|female|14.0|  0.0|  0.0| 7.8542|       S|  0.0|\n",
      "|       1|   2.0|female|55.0|  0.0|  0.0|   16.0|       S|  0.0|\n",
      "|       0|   3.0|  male| 2.0|  4.0|  1.0| 29.125|       Q|  0.0|\n",
      "|       1|   2.0|  male|29.7|  0.0|  0.0|   13.0|       S|  1.0|\n",
      "|       0|   3.0|female|31.0|  1.0|  0.0|   18.0|       S|  0.0|\n",
      "|       1|   3.0|female|29.7|  0.0|  0.0|  7.225|       C|  1.0|\n",
      "+--------+------+------+----+-----+-----+-------+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------+-------------------+------------------+------+------------------+------------------+-------------------+-----------------+--------+-------------------+\n",
      "|summary|           Survived|            Pclass|   Sex|               Age|             SibSp|              Parch|             Fare|Embarked|              AgeNA|\n",
      "+-------+-------------------+------------------+------+------------------+------------------+-------------------+-----------------+--------+-------------------+\n",
      "|  count|                889|               889|   889|               889|               889|                889|              889|     889|                889|\n",
      "|   mean|0.38245219347581555|2.3115860517435323|  null|29.653622047244184|0.5241844769403825|0.38245219347581555|32.09668087739029|    null|0.19910011248593926|\n",
      "| stddev|0.48625968831477334|0.8346997785705753|  null|12.968366933428964| 1.103704875596923| 0.8067607445174785|49.69750431670795|    null| 0.3995482811002537|\n",
      "|    min|                  0|               1.0|female|              0.42|               0.0|                0.0|              0.0|       C|                0.0|\n",
      "|    max|                  1|               3.0|  male|              80.0|               8.0|                6.0|         512.3292|       S|                1.0|\n",
      "+-------+-------------------+------------------+------+------------------+------------------+-------------------+-----------------+--------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# iii) Print the revised dataframe and recalculate the summary statistics. \n",
    "df.show()\n",
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i) Import all necessary pyspark functions.\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.feature import StandardScaler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ii) Create indexers and encoders for categorical string variables. \n",
    "# Call them [field]_indexer and [field]_encoder, respectively. For instance, gender_indexer and gender_encoder. \n",
    "\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
    "\n",
    "# StringIndexer\n",
    "si_Sex = StringIndexer(inputCol=\"Sex\",outputCol=\"Sex_indexer\")\n",
    "si_Embarked=StringIndexer(inputCol=\"Embarked\",outputCol=\"Embarked_indexer\")\n",
    "\n",
    "# OneHotEncoder\n",
    "oh_Sex = OneHotEncoder(inputCol=\"Sex_indexer\",outputCol=\"Sex_encoder\")\n",
    "#oh_Pclass = OneHotEncoder(inputCol=\"Pclass\",outputCol=\"Pclass_encoder\")\n",
    "#oh_SibSp = OneHotEncoder(inputCol=\"SibSp\",outputCol=\"SibSp_encoder\")\n",
    "#oh_Parch = OneHotEncoder(inputCol=\"Parch\",outputCol=\"Parch_encoder\")\n",
    "oh_Embarked=OneHotEncoder(inputCol=\"Embarked_indexer\",outputCol=\"Embarked_encoder\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The goal of this step is to assemble all feature columns into a feature vector in order to be used in the pipeline. \n",
    "# Tip: you can use the VectorAssembler to do this.\n",
    "df.dtypes\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "# assembler = VectorAssembler(\n",
    "#     inputCols=[\"Pclass_encoder\",\"Sex_encoder\",\"Age\",\"SibSp_encoder\",\"Parch_encoder\",\"Fare\",\"Embarked_encoder\",\"AgeNA\"],\n",
    "#     outputCol=\"features\")\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"Pclass\",\"Sex_encoder\",\"Age\",\"SibSp\",\"Parch\",\"Fare\",\"Embarked_encoder\",\"AgeNA\"],\n",
    "    outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create logistic regression model to be used in the pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr = LogisticRegression(labelCol=\"Survived\",featuresCol=\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble the pipeline\n",
    "from pyspark.ml import Pipeline\n",
    "#pl=Pipeline(stages=[si_Sex,si_Embarked,oh_Sex,oh_Pclass,oh_SibSp,oh_Parch,oh_Embarked,assembler,lr])\n",
    "pl=Pipeline(stages=[si_Sex,si_Embarked,oh_Sex,oh_Embarked,assembler,lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i) Use a 70-30 random split for the training and test sets, respectively. \n",
    "train, test = df.randomSplit([0.7, 0.3], seed = 29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7007874015748031 0.2992125984251969\n"
     ]
    }
   ],
   "source": [
    "# ii) Verify the size of each dataset after the split.\n",
    "print(train.count()/df.count(),test.count()/df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i) Fit the model using the predefined pipeline on the training set.\n",
    "model=pl.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ii) Use the fitted model for prediction on the test set.\n",
    "pred = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.ml.classification.BinaryLogisticRegressionTrainingSummary object at 0x0000024648940978>\n"
     ]
    }
   ],
   "source": [
    "# iii) Report the logistic regression coefficients. \n",
    "print(model.stages[-1].summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.0705783809790739,-2.5206792267576716,-0.03532335573370283,-0.29007011784877595,-0.08287229047753869,0.0008037718563865051,-0.5626823704920805,-0.13139324393926913,-0.5246659911084796]\n",
      "5.213189202682474\n"
     ]
    }
   ],
   "source": [
    "print(model.stages[-1].coefficients)\n",
    "print(model.stages[-1].intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+----+----+-----+-----+-------+--------+-----+-----------+----------------+-------------+----------------+--------------------+--------------------+--------------------+----------+\n",
      "|Survived|Pclass| Sex| Age|SibSp|Parch|   Fare|Embarked|AgeNA|Sex_indexer|Embarked_indexer|  Sex_encoder|Embarked_encoder|            features|       rawPrediction|         probability|prediction|\n",
      "+--------+------+----+----+-----+-----+-------+--------+-----+-----------+----------------+-------------+----------------+--------------------+--------------------+--------------------+----------+\n",
      "|       0|   1.0|male|18.0|  1.0|  0.0|  108.9|       C|  0.0|        0.0|             1.0|(1,[0],[1.0])|   (2,[1],[1.0])|[1.0,1.0,18.0,1.0...|[-0.6521785851115...|[0.34249876621813...|       1.0|\n",
      "|       0|   1.0|male|19.0|  3.0|  2.0|  263.0|       S|  0.0|        0.0|             0.0|(1,[0],[1.0])|   (2,[0],[1.0])|[1.0,1.0,19.0,3.0...|[0.43645747075845...|[0.60741459397417...|       0.0|\n",
      "|       0|   1.0|male|29.7|  0.0|  0.0|   39.6|       C|  1.0|        0.0|             1.0|(1,[0],[1.0])|   (2,[1],[1.0])|[1.0,1.0,29.7,0.0...|[0.05140193988008...|[0.51284765629823...|       0.0|\n",
      "|       0|   1.0|male|29.7|  0.0|  0.0|   52.0|       S|  1.0|        0.0|             0.0|(1,[0],[1.0])|   (2,[0],[1.0])|[1.0,1.0,29.7,0.0...|[0.47272429541370...|[0.61602835755718...|       0.0|\n",
      "|       0|   1.0|male|29.7|  0.0|  0.0|227.525|       C|  1.0|        0.0|             1.0|(1,[0],[1.0])|   (2,[1],[1.0])|[1.0,1.0,29.7,0.0...|[-0.0996468862313...|[0.47510887141023...|       1.0|\n",
      "+--------+------+----+----+-----+-----+-------+--------+-----+-----------+----------------+-------------+----------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# i) Print the first 5 rows of the results.\n",
    "pred.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Survived', 'int'),\n",
       " ('Pclass', 'double'),\n",
       " ('Sex', 'string'),\n",
       " ('Age', 'double'),\n",
       " ('SibSp', 'double'),\n",
       " ('Parch', 'double'),\n",
       " ('Fare', 'double'),\n",
       " ('Embarked', 'string'),\n",
       " ('AgeNA', 'double'),\n",
       " ('Sex_indexer', 'double'),\n",
       " ('Embarked_indexer', 'double'),\n",
       " ('Sex_encoder', 'vector'),\n",
       " ('Embarked_encoder', 'vector'),\n",
       " ('features', 'vector'),\n",
       " ('rawPrediction', 'vector'),\n",
       " ('probability', 'vector'),\n",
       " ('prediction', 'double')]"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8844339622641496"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ii) Report the AUC for this model.\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\",labelCol='Survived')\n",
    "evaluator.evaluate(pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
